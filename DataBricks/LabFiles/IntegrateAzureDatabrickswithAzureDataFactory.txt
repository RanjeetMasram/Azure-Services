
Demo : Using Azure Databricks with Azure Data Factory
-----------------------------------------------------------------------------------

Create a storage account named as "vetchstorage" and create a container named as "customercontainer"
Download the CustomerDetails-VtechBranchOne.json and load the file into the customercontainer of vtechstorage

Replace the APPLICATION-ID, AUTHENTICATION-KEY and TENANT-ID of your app registration in the below code

	spark.conf.set("dfs.adls.oauth2.access.token.provider.type", "ClientCredential")
	spark.conf.set("dfs.adls.oauth2.client.id", "<APPLICATION-ID>")
	spark.conf.set("dfs.adls.oauth2.credential", "<AUTHENTICATION-KEY>")
	spark.conf.set("dfs.adls.oauth2.refresh.url", "https://login.microsoftonline.com/<TENANT-ID>/oauth2/token")

If you have created the data lake and the container with different names , change the below code accordingly

	val customerDetails = spark.read.json("adl://datavtech.azuredatalakestore.net/datacontainer/CustomerDetails-VtechBranchOne.json")
	customerDetails.show()


Transform the data by selecting only few columns
	
	val specificColumns = customerDetails.select("CustomerId", "VehicleId", "DateOfPurchase")
	specificColumns.show()







